{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","cell_execution_strategy":"setup","authorship_tag":"ABX9TyMyvWhBMAQ7Vii86KzqHtRf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"y-6qcvQIu_d9"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"markdown","source":[],"metadata":{"id":"FEFE4UoFwgyd"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Colab Notebooks/HelloWorld\n","!ls"],"metadata":{"id":"GevBWn2Evqq-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas\n","import numpy as np\n","import torch\n","from torch import nn\n","from torch.utils.data import Dataset\n","from matplotlib import pyplot as plt"],"metadata":{"id":"h-trfjkMwgGe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","DEVICE"],"metadata":{"id":"GED2BjVixZhc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","class MnistDataset(Dataset):\n","    def __init__(self, csv_file):\n","        self.data_df = pandas.read_csv(csv_file, header=None)\n","\n","    def __len__(self):\n","        return len(self.data_df)\n","\n","    def __getitem__(self, index):\n","        label = self.data_df.iloc[index, 0]\n","        target = torch.zeros(10)\n","        target[label] = 1.0\n","        img_df = self.data_df.iloc[index, 1:].values\n","        image_values = torch.FloatTensor(img_df) / 255.0\n","        return label, image_values, target\n","\n","\n","class Discriminator(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.model = nn.Sequential(\n","            nn.Linear(784 + 10, 200),\n","            nn.LayerNorm(200),\n","            nn.LeakyReLU(0.02),\n","            nn.Linear(200, 1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, seed_tensor, label_tensor):\n","        inputs = torch.cat((seed_tensor, label_tensor))\n","        return self.model(inputs)\n","\n","\n","class Generator(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.model = nn.Sequential(\n","            nn.Linear(100 + 10, 200),\n","            nn.LayerNorm(200),\n","            nn.LeakyReLU(0.02),\n","            nn.Linear(200, 784),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, seed_tensor, label_tensor):\n","        inputs = torch.cat((seed_tensor, label_tensor))\n","        return self.model(inputs)\n","\n","\n","def generate_random_one_hot(size):\n","    label_tensor = torch.zeros(size)\n","    random_idx = np.random.randint(0, size)\n","    label_tensor[random_idx] = 1\n","    return label_tensor\n","\n","\n","def generate_random(size):\n","    random_data = torch.randn(size)\n","    return random_data\n"],"metadata":{"id":"EOWoM6_cxoys"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","train_dataset = MnistDataset('mnist_train.csv')\n","\n","discriminator_net = Discriminator().to(DEVICE)\n","generator_net = Generator().to(DEVICE)\n","loss_function = torch.nn.BCELoss()\n","\n","optimizer_d = torch.optim.Adam(discriminator_net.parameters())\n","optimizer_g = torch.optim.Adam(generator_net.parameters())\n","\n","progress_d_real = []\n","progress_d_fake = []\n","progress_g = []\n","counter = 0\n","real_label = torch.FloatTensor([1.0]).to(DEVICE)\n","fake_label = torch.FloatTensor([0.0]).to(DEVICE)\n"],"metadata":{"id":"FaGqskDpycSV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_conditional_images(label):\n","    label_tensor = torch.zeros(10)\n","    label_tensor[label] = 1.0\n","    f, ax_arr = plt.subplots(2, 3, figsize=(16, 8))\n","    for i in range(2):\n","        for j in range(3):\n","            output = generator_net(generate_random(100).to(DEVICE),label_tensor.to(DEVICE))\n","            img = output.detach().cpu().numpy().reshape(28, 28)\n","            ax_arr[i, j].imshow(img, interpolation='None', cmap='Blues')\n","    plt.show()"],"metadata":{"id":"HeDV1gDcy752"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","for i in range(10):\n","    for label, real_data, target in train_dataset:\n","        discriminator_net.zero_grad()\n","        output = discriminator_net(real_data.to(DEVICE), target.to(DEVICE))\n","        loss_d_real = loss_function(output, real_label)\n","        random_label = generate_random_one_hot(10).to(DEVICE)\n","        gen_img = generator_net(generate_random(100).to(DEVICE),random_label)\n","        output = discriminator_net(gen_img.detach(), random_label)\n","        loss_d_fake = loss_function(output, fake_label)\n","        loss_d = loss_d_real + loss_d_fake\n","        optimizer_d.zero_grad()\n","        loss_d.backward()\n","        optimizer_d.step()\n","\n","        generator_net.zero_grad()\n","        gen_img = generator_net(generate_random(100).to(DEVICE),random_label)\n","        output = discriminator_net(gen_img,random_label)\n","        loss_g = loss_function(output, real_label)\n","        optimizer_g.zero_grad()\n","        loss_g.backward()\n","        optimizer_g.step()\n","\n","        counter += 1\n","        if counter % 500 == 0:\n","            progress_d_real.append(loss_d_real.item())\n","            progress_d_fake.append(loss_d_fake.item())\n","            progress_g.append(loss_g.item())\n","        if counter % 10000 == 0:\n","            print(f'epoch = {i + 1}, counter = {counter}')\n","\n","    plot_conditional_images(9)\n"],"metadata":{"id":"S1o7Dhg6yvcF"},"execution_count":null,"outputs":[]}]}